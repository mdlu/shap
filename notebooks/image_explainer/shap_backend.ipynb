{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP (SHapley Additive exPlanations)\n",
    "Explaining model output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary Python imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import shap\n",
    "import sys\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlopen\n",
    "import random\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.layers import Input, Lambda\n",
    "from keras import Model\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import requests\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_image(url, preprocess):\n",
    "  response = requests.get(url)\n",
    "  img = Image.open(BytesIO(response.content))\n",
    "  if img.mode != 'RGB':\n",
    "      img = img.convert('RGB')\n",
    "  x = np.array(img.resize((224, 224)))\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  if preprocess:  \n",
    "    return preprocess_input(x), img.size\n",
    "  return x, img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_model():\n",
    "  keras_model = ResNet50(input_shape=[224, 224, 3], weights='imagenet', include_top=False, pooling='avg')\n",
    "  im1 = Input([224, 224, 3])\n",
    "  f1 = keras_model(im1)\n",
    "  return keras_model, im1, f1\n",
    "\n",
    "def inv_logit(y):\n",
    "    return tf.math.log(y/(1-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "im2_const = tf.placeholder(tf.float32, [1, 224, 224, 3])\n",
    "im2 = Lambda(lambda im1: im2_const)(im1)\n",
    "f2 = keras_model(im2)\n",
    "d = keras.layers.Dot(1, normalize=True)([f1, f2])\n",
    "logit = Lambda(lambda d: inv_logit((d+1)/2))(d)\n",
    "model = Model(inputs=[im1], outputs=[logit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute(original_url):\n",
    "  training_img, training_img_size = prep_image(original_url, True)\n",
    "  x_train = np.array(gaussian_filter(training_img, sigma=10))\n",
    "  e = shap.DeepExplainer(model, x_train, img_dict = {im2_const: training_img})\n",
    "  return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_match(match_url, e):\n",
    "  start = time.time()\n",
    "  test_image, size = prep_image(match_url, True)\n",
    "  no_preprocess, _ = prep_image(match_url, False)\n",
    "  x_test = np.array(test_image)\n",
    "  shap_values = e.shap_values(x_test, check_additivity=False)\n",
    "  shap_values_normed = np.array(shap_values)\n",
    "  shap_values_normed = np.linalg.norm(shap_values_normed, axis=4)\n",
    "  \n",
    "  blurred = gaussian_filter(shap_values_normed[0], sigma=4)\n",
    "  bflat = blurred.flatten()\n",
    "  shap_values_mask_qi = np.where(np.array(blurred) > np.mean(bflat) + np.std(bflat), 1, 0).reshape(224, 224, 1)\n",
    "  shap_values_qi = np.multiply(shap_values_mask_qi, x_test[0])\n",
    "  \n",
    "  new_size = (224, int(size[1]/size[0]*224)) if size[0] > size[1] else (int(size[0]/size[1]*224), 224)\n",
    "  original_size = Image.fromarray(shap_values_qi.astype(np.uint8), 'RGB').resize(new_size)\n",
    "  \n",
    "#   end = time.time()\n",
    "#   print(end-start)\n",
    "#   imgs = shap.image_plot(shap_values, no_preprocess.astype(float))\n",
    "#   return imgs\n",
    "  return original_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def setup_model():\n",
    "#   keras_model = ResNet50(input_shape=[224, 224, 3], weights='imagenet', include_top=False, pooling='avg')\n",
    "#   im1 = Input([224, 224, 3])\n",
    "#   f1 = keras_model(im1)\n",
    "#   return keras_model, im1, f1\n",
    "\n",
    "# def inv_logit(y):\n",
    "#     return tf.math.log(y/(1-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def precompute(original_url):\n",
    "#   training_img, training_img_size = prep_image(original_url, True)\n",
    "#   x_train = np.array(gaussian_filter(training_img, sigma=10))\n",
    "  \n",
    "#   query_img, query_img_size = prep_image(original_url, True)\n",
    "#   im2_const = tf.constant(query_img, dtype=tf.float32)\n",
    "#   im2 = Lambda(lambda im1: im2_const)(im1)\n",
    "\n",
    "#   f2 = keras_model(im2)\n",
    "#   d = keras.layers.Dot(1, normalize=True)([f1, f2])\n",
    "\n",
    "#   logit = Lambda(lambda d: inv_logit((d+1)/2))(d)\n",
    "#   model = Model(inputs=[im1], outputs=[logit])\n",
    "  \n",
    "#   e = shap.DeepExplainer(model, x_train)\n",
    "#   return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_match(match_url, e):\n",
    "#   start = time.time()\n",
    "#   test_image, size = prep_image(match_url, True)\n",
    "#   no_preprocess, _ = prep_image(match_url, False)\n",
    "#   x_test = np.array(test_image)\n",
    "#   shap_values = e.shap_values(x_test, check_additivity=False)\n",
    "#   shap_values_normed = np.array(shap_values)\n",
    "#   shap_values_normed = np.linalg.norm(shap_values_normed, axis=4)\n",
    "  \n",
    "#   blurred = gaussian_filter(shap_values_normed[0], sigma=4)\n",
    "#   bflat = blurred.flatten()\n",
    "#   shap_values_mask_qi = np.where(np.array(blurred) > np.mean(bflat) + np.std(bflat), 1, 0).reshape(224, 224, 1)\n",
    "#   shap_values_qi = np.multiply(shap_values_mask_qi, x_test[0])\n",
    "  \n",
    "#   new_size = (224, int(size[1]/size[0]*224)) if size[0] > size[1] else (int(size[0]/size[1]*224), 224)\n",
    "#   original_size = Image.fromarray(shap_values_qi.astype(np.uint8), 'RGB').resize(new_size)\n",
    "  \n",
    "#   end = time.time()\n",
    "#   print(end-start)\n",
    "#   imgs = shap.image_plot(shap_values, no_preprocess.astype(float))\n",
    "#   return imgs\n",
    "# #   return original_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\v-mindlu\\AppData\\Local\\Continuum\\anaconda3\\envs\\final\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\v-mindlu\\AppData\\Local\\Continuum\\anaconda3\\envs\\final\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\v-mindlu\\AppData\\Local\\Continuum\\anaconda3\\envs\\final\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\v-mindlu\\AppData\\Local\\Continuum\\anaconda3\\envs\\final\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\v-mindlu\\AppData\\Local\\Continuum\\anaconda3\\envs\\final\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\v-mindlu\\AppData\\Local\\Continuum\\anaconda3\\envs\\final\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\v-mindlu\\AppData\\Local\\Continuum\\anaconda3\\envs\\final\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "18.252468824386597\n"
     ]
    }
   ],
   "source": [
    "# run before any queries\n",
    "start = time.time()\n",
    "keras_model, im1, f1 = setup_model()\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3403663635253906\n"
     ]
    }
   ],
   "source": [
    "# run only once for each original image\n",
    "start = time.time()\n",
    "original_url = \"https://mmlsparkdemo.blob.core.windows.net/cknn/datasets/interpret/lex1.jpg\" # replace with link to original image\n",
    "e = precompute(original_url)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5744669437408447\n"
     ]
    }
   ],
   "source": [
    "# run once for each match\n",
    "start = time.time()\n",
    "match_url = \"https://mmlsparkdemo.blob.core.windows.net/cknn/datasets/interpret/lex2.jpg\" # replace with link to matched image\n",
    "explained_pic = test_match(match_url, e)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ],
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "name": "shap_backend",
  "notebookId": 1335601457952439
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
